ifndef::imagesdir[:imagesdir: ../images]

[[section-concepts]]
== Cross-cutting Concepts


[role="arc42help"]
****
.Content
This section describes overall, principal regulations and solution ideas that are relevant in multiple parts (= cross-cutting) of your system.
Such concepts are often related to multiple building blocks.
They can include many different topics, such as

* models, especially domain models
* architecture or design patterns
* rules for using specific technology
* principal, often technical decisions of an overarching (= cross-cutting) nature
* implementation rules


.Motivation
Concepts form the basis for _conceptual integrity_ (consistency, homogeneity) of the architecture. 
Thus, they are an important contribution to achieve inner qualities of your system.

Some of these concepts cannot be assigned to individual building blocks, e.g. security or safety. 


.Form
The form can be varied:

* concept papers with any kind of structure
* cross-cutting model excerpts or scenarios using notations of the architecture views
* sample implementations, especially for technical concepts
* reference to typical usage of standard frameworks (e.g. using Hibernate for object/relational mapping)

.Structure
A potential (but not mandatory) structure for this section could be:

* Domain concepts
* User Experience concepts (UX)
* Safety and security concepts
* Architecture and design patterns
* "Under-the-hood"
* development concepts
* operational concepts

Note: it might be difficult to assign individual concepts to one specific topic
on this list.

image::08-Crosscutting-Concepts-Structure-EN.png["Possible topics for crosscutting concepts"]


.Further Information

See https://docs.arc42.org/section-8/[Concepts] in the arc42 documentation.
****


=== Domain Concepts

==== Question

In our app, the question is always represent as a data structure with the next format: 

[listing]
----
{
    text: "What is the capital of Asturias?"
    answers: [Gijón,Oviedo,Cangas de Onís]
    correctIndex: 1
}
----


*Benefits:*

- Consistency: This format ensures consistent representation of questions throughout the app, reducing errors and simplifying code maintenance.
- Clarity: By explicitly defining the data format, developers can clearly understand how to work with question data within the codebase.
- Flexibility: By defining an array and a correct index, the array could be of multiple sizes.


=== UX Concepts

==== Color 

We decided to use a color palette of 4 colors:


[cols="1,1"]
|===
| Name | Color
| Background | +++<span style="color: #191919; font-weight:bold">#191919</span>+++
| Text| +++<span style="background-color: #191919;color: #f2ecff; font-weight:bold">#f2ecff</span>+++
| Primary | +++<span style="color: #00c896; font-weight:bold">#00c896</span>+++
| Danger | +++<span style="color: #e35a2a; font-weight:bold">#e35a2a</span>+++
|===

*Benefits:*

 - Clarity: Thanks to this simple palette it is very easy to identify when something is correct or not.
 - Consistency: By using a limited set of colors, the overall visual design of the application will be cohesive and harmonious.
 - Accessibility: The chosen colors provide good contrast ratios, ensuring the content is readable and accessible for users with various visual abilities.
 - Branding: The selected colors can be used to reinforce the application's brand identity and make it recognizable to users.

The chosen color palette strikes a balance between functionality, aesthetics, and branding. The dark background with light text provides a high-contrast theme that is easy on the eyes, while the primary and danger colors are used sparingly to highlight important information or actions.





=== Development concepts

==== Testing and Monitoring
 - Unit Testing: We employed the SonarCloud tool to monitor the code covered by these tests, while Continuous Integration practices were implemented using GitHub Actions.
 - Load Testing and Monitoring: We used Gattling for recording user simulations that consist on login into the application, playing the existing game modes and checking the statistics and leaderboards. Then, Gatling allowed us to also measure the performance of the application and the average response times when creating 2, 5, 10 and 25 users per second during 60 seconds performing the previously mentioned simulations, using 2 different Azure machines. 
 Particularly, load testing has been performed using a 1-cpu machine with almost 1GB of RAM memory and also, using a 2-cpu machine with 8GB of RAM memory.
  
  ** 1-cpu machine 
  
  With this machine all requests were answered quickly when 2 users per second where created (120 users in total) with almost all requests responding in less than 1 second with a minimum response time of just 24 milliseconds and a maximum reponse time of 1.6 seconds.
    
image::2users-secA.png["2 users per second in 60 seconds user-simulation overall results with 1-cpu machine"]
image::2users-secB.png["2 users per second in 60 seconds user-simulation specific graph results with 1-cpu machine"]

    When creating 5 users per second (350 users in total), the responses took almost all of them (around 80%) less than a second with a minimum response time of 24 milliseconds, but with a maximum response time of 10 seconds which is a huge amount of time for a web application.
   
image::5users-secA.png["5 users per second in 60 seconds user-simulation overall results with 1-cpu machine"]
image::5users-secB.png["5 users per second in 60 seconds user-simulation specific graph results with 1-cpu machine"]

    Unfortunately, when creating a load of 10 user per second (600 users in total) 41% of the responses were failling and around 70% of the responses where failing or taking more than a second to be answered. For sure, when creating even more load, almost all response were going to fail.

image::10users-secA.png["10 users per second in 60 seconds user-simulation overall results with 1-cpu machine"]
image::10users-secB.png["10 users per second in 60 seconds user-simulation specific graph results with 1-cpu machine"]

    With this 1-cpu and 1GB of RAM azure machine we could afford around 200 hundred users making constant resquests without having a denial of service and providing reasonable requests' response times.

 ** 2-cpu machine 

    With this machine all requests were answered quickly when 2 users per second where created (120 users in total) with almost all requests responding in less than 1 second with a minimum response time of just 24 milliseconds and a maximum reponse time of 1.8 seconds.
    
image::2-2users-secA.png["2 users per second in 60 seconds user-simulation overall results"]
image::2-2users-secB.png["2 users per second in 60 seconds user-simulation specific graph results"]

    When creating 5 users per second (350 users in total), the responses took almost all of them (around 80%) less than a second with a minimum response time of 24 milliseconds, but with a maximum response time of 10 seconds which is exactly the same time we obtained with the other machine and a similar mean response time.
   
image::2-5users-secA.png["5 users per second in 60 seconds user-simulation overall results with 2-cpu machine"]
image::2-5users-secB.png["5 users per second in 60 seconds user-simulation specific graph results with 2-cpu machine"]

    When creating a load of 10 user per second (600 users in total), no response failed although the maximum response time was 58 seconds with a mean response time of 2 seconds, which meant that almost every respone took less than a second.

image::2-10users-secA.png["10 users per second in 60 seconds user-simulation overall results with 2-cpu machine"]
image::2-10users-secB.png["10 users per second in 60 seconds user-simulation specific graph results with 2-cpu machine"]

    Finally, when creating a load of 25 user per second (1500 users in total), just a 7% of the total amount of response failed and the maximum response time was 60 seconds with a mean response time of 5 seconds.

image::2-10users-secA.png["25 users per second in 60 seconds user-simulation overall results with 2-cpu machine"]
image::2-10users-secB.png["25 users per second in 60 seconds user-simulation specific graph results with 2-cpu machine"]

    Using this 2-cpu and 8GB machine, response times are not enhaced when using more powerfull hardware and most of the work should be done programatically by improving our software. 
    But better hardware allows us to support much more load on the application, which means more users playing at the same time. This time, we could support more 400, but less than 800 simultaneous users.
    Taking a look at the specific graph results of each of thesimulations performed, most of load is always provoked at the beggining of the simulation when the users have to login. 
    Then, when users are playing some games the amount of response is reduced a lot since all the information for playing the game is asked at the beggining.

    As a general conclusion, following the azure payment plan for virtual machines: With low load requirements and just paying around 35$ each month we could afford a 1-cpu and 1GB RAM memory web server supporting around 200 simultaneous users using the application at the same time.
    On the contrary, if higher load requirements are needed and paying around 100$ for a 2-cpu and 8GB of RAM memory server, the amount of supported users is more than duplicated supporting more than 400 simultaneous users. 


 - E2e Testing: We used behavior-driven development scenarios written in the Gherking language as a basis for our end-to-end tests.

==== Deployment
The application is deployed using Docker.

==== Configurability
The application has simple configurable game features for selecting between two game modes (normal/usual and trivia game mode) and two difficulty levels (easy and hard difficulties).
 - Normal mode game consists of 10 random questions with an amount of time to answer the question before losing the possibility to answer. Easy and hard modes differ on the amount of time that the user has to answer the question. 
 - Trivia mode game consists of 10 questions, which are generated based on the resulting category of rolling a dice. There are 6 possible categories: sports, science, history, geography and entertainment.
Additionally, there is an option at the main application view where random music can be played.


...

